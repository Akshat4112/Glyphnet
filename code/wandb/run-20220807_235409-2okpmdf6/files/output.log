[name: "/device:CPU:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 5109127863070086932
xla_global_id: -1
]
Before datagen..
Found 2800 images belonging to 2 classes.
Datagen completed..
Found 800 images belonging to 2 classes.
Data Generation Completed
Training Starting..
Epoch 1/30
/home/akshat/Documents/Github/homo_env/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  super(RMSprop, self).__init__(name, **kwargs)
[34m[1mwandb[39m[22m: [33mWARNING[39m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.
WARNING:tensorflow:From /home/akshat/Documents/Github/homo_env/lib/python3.10/site-packages/tensorflow/python/profiler/internal/flops_registry.py:138: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`





































500/500 [==============================] - ETA: 0s - loss: 0.6933 - acc: 0.4560
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.

500/500 [==============================] - 104s 199ms/step - loss: 0.6933 - acc: 0.4560 - val_loss: 0.6932 - val_acc: 0.5000
Epoch 2/30




































500/500 [==============================] - ETA: 0s - loss: 0.6933 - acc: 0.4600
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.
500/500 [==============================] - 97s 193ms/step - loss: 0.6933 - acc: 0.4600 - val_loss: 0.6931 - val_acc: 0.5000
Epoch 3/30




































500/500 [==============================] - 95s 190ms/step - loss: 0.6931 - acc: 0.4720 - val_loss: 0.6931 - val_acc: 0.5000
Epoch 4/30





































500/500 [==============================] - ETA: 0s - loss: 0.6932 - acc: 0.4740
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.
500/500 [==============================] - 97s 195ms/step - loss: 0.6932 - acc: 0.4740 - val_loss: 0.6931 - val_acc: 0.5000
Epoch 5/30



































500/500 [==============================] - 96s 192ms/step - loss: 0.6932 - acc: 0.4760 - val_loss: 0.6931 - val_acc: 0.5000
Epoch 6/30







































500/500 [==============================] - 95s 191ms/step - loss: 0.6931 - acc: 0.5080 - val_loss: 0.6931 - val_acc: 0.5000
Epoch 7/30








































500/500 [==============================] - 96s 192ms/step - loss: 0.6932 - acc: 0.4720 - val_loss: 0.6931 - val_acc: 0.5000
Epoch 8/30




































500/500 [==============================] - 90s 180ms/step - loss: 0.6932 - acc: 0.5020 - val_loss: 0.6931 - val_acc: 0.5000
Epoch 9/30





































500/500 [==============================] - 94s 188ms/step - loss: 0.6932 - acc: 0.5080 - val_loss: 0.6931 - val_acc: 0.5000
Epoch 10/30







































500/500 [==============================] - 95s 189ms/step - loss: 0.6930 - acc: 0.5300 - val_loss: 0.6932 - val_acc: 0.5000
Epoch 11/30





































500/500 [==============================] - 89s 178ms/step - loss: 0.6928 - acc: 0.5480 - val_loss: 0.6932 - val_acc: 0.5000
Epoch 12/30



































500/500 [==============================] - 88s 176ms/step - loss: 0.6933 - acc: 0.4840 - val_loss: 0.6932 - val_acc: 0.5000
Epoch 13/30





































500/500 [==============================] - 91s 183ms/step - loss: 0.6932 - acc: 0.4980 - val_loss: 0.6932 - val_acc: 0.5000
Epoch 14/30






































500/500 [==============================] - 92s 185ms/step - loss: 0.6932 - acc: 0.4980 - val_loss: 0.6932 - val_acc: 0.5000
Epoch 15/30


































500/500 [==============================] - 88s 176ms/step - loss: 0.6930 - acc: 0.5180 - val_loss: 0.6932 - val_acc: 0.5000
Epoch 16/30






































500/500 [==============================] - 92s 184ms/step - loss: 0.6932 - acc: 0.5020 - val_loss: 0.6932 - val_acc: 0.5000
Epoch 17/30



































500/500 [==============================] - 88s 176ms/step - loss: 0.6929 - acc: 0.5280 - val_loss: 0.6932 - val_acc: 0.5000
Epoch 18/30






































500/500 [==============================] - 92s 183ms/step - loss: 0.6934 - acc: 0.4820 - val_loss: 0.6932 - val_acc: 0.5000
Epoch 19/30



































500/500 [==============================] - 87s 175ms/step - loss: 0.6934 - acc: 0.4800 - val_loss: 0.6932 - val_acc: 0.5000
Epoch 20/30




































500/500 [==============================] - 91s 183ms/step - loss: 0.6933 - acc: 0.4760 - val_loss: 0.6931 - val_acc: 0.5000
Epoch 21/30






































500/500 [==============================] - 93s 186ms/step - loss: 0.6933 - acc: 0.4580 - val_loss: 0.6931 - val_acc: 0.5000
Epoch 22/30





































500/500 [==============================] - 93s 185ms/step - loss: 0.6932 - acc: 0.5040 - val_loss: 0.6931 - val_acc: 0.5000
Epoch 23/30





































500/500 [==============================] - 93s 186ms/step - loss: 0.6932 - acc: 0.5020 - val_loss: 0.6931 - val_acc: 0.5000
Epoch 24/30






































500/500 [==============================] - 94s 187ms/step - loss: 0.6931 - acc: 0.5140 - val_loss: 0.6931 - val_acc: 0.5000
Epoch 25/30





































500/500 [==============================] - 93s 186ms/step - loss: 0.6931 - acc: 0.5080 - val_loss: 0.6931 - val_acc: 0.5000
Epoch 26/30






































500/500 [==============================] - 94s 187ms/step - loss: 0.6932 - acc: 0.4820 - val_loss: 0.6931 - val_acc: 0.5000
Epoch 27/30






































500/500 [==============================] - 93s 187ms/step - loss: 0.6931 - acc: 0.5240 - val_loss: 0.6931 - val_acc: 0.5000
Epoch 28/30





































500/500 [==============================] - 93s 187ms/step - loss: 0.6931 - acc: 0.5080 - val_loss: 0.6931 - val_acc: 0.5000
Epoch 29/30





































500/500 [==============================] - 93s 187ms/step - loss: 0.6931 - acc: 0.5100 - val_loss: 0.6932 - val_acc: 0.5000
Epoch 30/30






































500/500 [==============================] - 95s 190ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5000
Training Completed..